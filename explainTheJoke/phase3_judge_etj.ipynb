{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454,
          "referenced_widgets": [
            "8259e335c4e04e08afe9c41716b56b87",
            "2fa2c34860d5475fbcf395d23ca1ccd2",
            "b270e0c8980f4ab79bf9ccdfc0ce658b",
            "391c913a189c4e30ae4ab3bbea5241db",
            "912f97e24ddc4ca2a66aa59b0175ac58",
            "d65f6a1a0d9f45d88f1e7797faaa9066",
            "dee0f80139ce4c04b7e9a5c1597d04b7",
            "859e77f9a3a14b1bb783d4c8c833103c",
            "e34a1fbfe9304106bbc339e562f3ee59",
            "4ca5b24547564699ba521acc003691af",
            "012954322f7c4ca4b778da85910a1e13"
          ]
        },
        "id": "yjeKr_gZD2iu",
        "outputId": "1c861fe5-457e-44fa-d71d-bb21591d36d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8259e335c4e04e08afe9c41716b56b87",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Loading explanations ===\n",
            "Scoring 377 joke pairs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Judging:   0%|          | 0/377 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Judging: 100%|██████████| 377/377 [52:01<00:00,  8.28s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== RESULTS ===\n",
            "tie: 275 (72.9%)\n",
            "audio: 39 (10.3%)\n",
            "text: 63 (16.7%)\n",
            "\n",
            "Wrote: cache/joke_judge_independent_scoring.jsonl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "\n",
        "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "MAX_NEW_TOKENS = 120\n",
        "\n",
        "TEXT_PATH  = \"cache/joke_explanations_qwen.jsonl\"\n",
        "AUDIO_PATH = \"cache/joke_explanations_qwen_audio.jsonl\"\n",
        "\n",
        "OUT_PATH = \"cache/joke_judge_independent_scoring.jsonl\"\n",
        "\n",
        "# ---------------- SCORING PROMPT ----------------\n",
        "\n",
        "JUDGE_PROMPT = \"\"\"You are a strict evaluator of joke explanations.\n",
        "\n",
        "Task:\n",
        "Evaluate how well the explanation explains WHY the joke is humorous.\n",
        "\n",
        "Evaluation criteria:\n",
        "- Correct identification of the humor mechanism (e.g., wordplay, ambiguity, violated expectation)\n",
        "- Clarity and correctness\n",
        "- No hallucinated or irrelevant mechanisms\n",
        "\n",
        "Score the explanation on a scale from 1 to 5:\n",
        "1 = very poor\n",
        "2 = poor\n",
        "3 = acceptable\n",
        "4 = good\n",
        "5 = excellent\n",
        "\n",
        "Return ONLY valid JSON in exactly this format:\n",
        "{{\"Score\": 1 | 2 | 3 | 4 | 5,\n",
        " \"Reason\": \"<short justification>\"}}\n",
        "\n",
        "Joke:\n",
        "{joke}\n",
        "\n",
        "Explanation:\n",
        "{exp}\n",
        "\"\"\"\n",
        "\n",
        "# --------------- MODEL ----------------\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ").eval()\n",
        "\n",
        "# --------------- HELPERS ----------------\n",
        "\n",
        "def load_map(path):\n",
        "    with open(path, encoding=\"utf-8\") as f:\n",
        "        return {obj[\"id\"]: obj for obj in map(json.loads, f)}\n",
        "\n",
        "def safe_json_extract(text):\n",
        "    start = text.find(\"{\")\n",
        "    if start == -1:\n",
        "        return None\n",
        "\n",
        "    depth = 0\n",
        "    for i in range(start, len(text)):\n",
        "        if text[i] == \"{\":\n",
        "            depth += 1\n",
        "        elif text[i] == \"}\":\n",
        "            depth -= 1\n",
        "            if depth == 0:\n",
        "                try:\n",
        "                    return json.loads(text[start:i+1])\n",
        "                except Exception:\n",
        "                    return None\n",
        "    return None\n",
        "\n",
        "def generate_score(prompt: str):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a judge that outputs ONLY valid JSON.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ]\n",
        "\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        return_tensors=\"pt\",\n",
        "        add_generation_prompt=True,\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        out = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=MAX_NEW_TOKENS,\n",
        "            do_sample=False,\n",
        "            temperature=0.0,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
        "    decoded = tokenizer.decode(\n",
        "        out[0][prompt_len:],\n",
        "        skip_special_tokens=True,\n",
        "    )\n",
        "\n",
        "    parsed = safe_json_extract(decoded)\n",
        "    if parsed is None:\n",
        "        return {\"Score\": 0, \"Reason\": \"Parse failure\"}\n",
        "\n",
        "    return parsed\n",
        "\n",
        "# --------------- RUN -----------------\n",
        "\n",
        "def run_judge():\n",
        "    print(\"=== Loading explanations ===\")\n",
        "\n",
        "    text_items = load_map(TEXT_PATH)\n",
        "    audio_items = load_map(AUDIO_PATH)\n",
        "\n",
        "    ids = sorted(set(text_items) & set(audio_items))\n",
        "    votes = Counter()\n",
        "\n",
        "    print(f\"Scoring {len(ids)} joke pairs\")\n",
        "\n",
        "    with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
        "        for i in tqdm(ids, desc=\"Judging\"):\n",
        "            t = text_items[i]\n",
        "            a = audio_items[i]\n",
        "\n",
        "            judge_text = generate_score(\n",
        "                JUDGE_PROMPT.format(\n",
        "                    joke=t[\"Joke\"],\n",
        "                    exp=t[\"Explanation\"],\n",
        "                )\n",
        "            )\n",
        "\n",
        "            judge_audio = generate_score(\n",
        "                JUDGE_PROMPT.format(\n",
        "                    joke=a[\"Joke\"],\n",
        "                    exp=a[\"Explanation\"],\n",
        "                )\n",
        "            )\n",
        "\n",
        "            s_text = int(judge_text.get(\"Score\", 0))\n",
        "            s_audio = int(judge_audio.get(\"Score\", 0))\n",
        "\n",
        "            if s_text > s_audio:\n",
        "                final = \"text\"\n",
        "            elif s_audio > s_text:\n",
        "                final = \"audio\"\n",
        "            else:\n",
        "                final = \"tie\"\n",
        "\n",
        "            votes[final] += 1\n",
        "\n",
        "            out = {\n",
        "                \"id\": i,\n",
        "                \"text_score\": s_text,\n",
        "                \"audio_score\": s_audio,\n",
        "                \"final_decision\": final,\n",
        "                \"text_judge\": judge_text,\n",
        "                \"audio_judge\": judge_audio,\n",
        "            }\n",
        "\n",
        "            f.write(json.dumps(out, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    # ------------- STATS -------------\n",
        "\n",
        "    total = sum(votes.values())\n",
        "    print(\"\\n=== RESULTS ===\")\n",
        "    for k, v in votes.items():\n",
        "        pct = (v / total * 100) if total else 0.0\n",
        "        print(f\"{k}: {v} ({pct:.1f}%)\")\n",
        "\n",
        "    print(\"\\nWrote:\", OUT_PATH)\n",
        "\n",
        "# ------------- MAIN --------------\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_judge()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "012954322f7c4ca4b778da85910a1e13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fa2c34860d5475fbcf395d23ca1ccd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d65f6a1a0d9f45d88f1e7797faaa9066",
            "placeholder": "​",
            "style": "IPY_MODEL_dee0f80139ce4c04b7e9a5c1597d04b7",
            "value": "Loading weights: 100%"
          }
        },
        "391c913a189c4e30ae4ab3bbea5241db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca5b24547564699ba521acc003691af",
            "placeholder": "​",
            "style": "IPY_MODEL_012954322f7c4ca4b778da85910a1e13",
            "value": " 291/291 [00:04&lt;00:00, 55.24it/s, Materializing param=model.norm.weight]"
          }
        },
        "4ca5b24547564699ba521acc003691af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8259e335c4e04e08afe9c41716b56b87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2fa2c34860d5475fbcf395d23ca1ccd2",
              "IPY_MODEL_b270e0c8980f4ab79bf9ccdfc0ce658b",
              "IPY_MODEL_391c913a189c4e30ae4ab3bbea5241db"
            ],
            "layout": "IPY_MODEL_912f97e24ddc4ca2a66aa59b0175ac58"
          }
        },
        "859e77f9a3a14b1bb783d4c8c833103c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "912f97e24ddc4ca2a66aa59b0175ac58": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b270e0c8980f4ab79bf9ccdfc0ce658b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_859e77f9a3a14b1bb783d4c8c833103c",
            "max": 291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e34a1fbfe9304106bbc339e562f3ee59",
            "value": 291
          }
        },
        "d65f6a1a0d9f45d88f1e7797faaa9066": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dee0f80139ce4c04b7e9a5c1597d04b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e34a1fbfe9304106bbc339e562f3ee59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
